{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a785aae7",
   "metadata": {},
   "source": [
    "# Evaluation Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b6722a",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed6cfeb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from typing import Union, Literal, Dict, Optional, Tuple\n",
    "\n",
    "from eval import read_run_dir, get_err_from_run, compute_scaling_err, get_timed_err_from_run\n",
    "from plot_utils import plot_model_errs\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "sns.set_theme('notebook', 'darkgrid')\n",
    "palette = sns.color_palette('colorblind')\n",
    "\n",
    "run_dir = \"../models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e8d018b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>task</th>\n",
       "      <th>model</th>\n",
       "      <th>kwargs</th>\n",
       "      <th>num_tasks</th>\n",
       "      <th>num_examples</th>\n",
       "      <th>n_dims</th>\n",
       "      <th>n_layer</th>\n",
       "      <th>n_head</th>\n",
       "      <th>run_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pretrained</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>depth=4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>decision_tree_pretrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pretrained_quantized</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>depth=4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>decision_tree_pretrained_quant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pretrained_relu</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>Transformer-ReLU</td>\n",
       "      <td>depth=4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>decision_tree_standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pretrained_relu_quantized</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>Transformer-ReLU</td>\n",
       "      <td>depth=4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>decision_tree_standard_quant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pretrained</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>Transformer</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>linear_regression_pretrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pretrained_quantized</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>Transformer</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>linear_regression_pretrained_quant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pretrained_relu</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>Transformer-ReLU</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>linear_regression_standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pretrained_relu_quantized</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>Transformer-ReLU</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>linear_regression_standard_quant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pretrained</td>\n",
       "      <td>sparse_linear_regression</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>sparsity=3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>sparse_regression_pretrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pretrained_quantized</td>\n",
       "      <td>sparse_linear_regression</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>sparsity=3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>sparse_regression_pretrained_quant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pretrained_relu</td>\n",
       "      <td>sparse_linear_regression</td>\n",
       "      <td>Transformer-ReLU</td>\n",
       "      <td>sparsity=3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>sparse_regression_standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pretrained_relu_quantized</td>\n",
       "      <td>sparse_linear_regression</td>\n",
       "      <td>Transformer-ReLU</td>\n",
       "      <td>sparsity=3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>sparse_regression_standard_quant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       run_id                      task             model  \\\n",
       "5                  pretrained             decision_tree       Transformer   \n",
       "6        pretrained_quantized             decision_tree       Transformer   \n",
       "7             pretrained_relu             decision_tree  Transformer-ReLU   \n",
       "4   pretrained_relu_quantized             decision_tree  Transformer-ReLU   \n",
       "9                  pretrained         linear_regression       Transformer   \n",
       "10       pretrained_quantized         linear_regression       Transformer   \n",
       "11            pretrained_relu         linear_regression  Transformer-ReLU   \n",
       "8   pretrained_relu_quantized         linear_regression  Transformer-ReLU   \n",
       "1                  pretrained  sparse_linear_regression       Transformer   \n",
       "2        pretrained_quantized  sparse_linear_regression       Transformer   \n",
       "3             pretrained_relu  sparse_linear_regression  Transformer-ReLU   \n",
       "0   pretrained_relu_quantized  sparse_linear_regression  Transformer-ReLU   \n",
       "\n",
       "        kwargs  num_tasks  num_examples  n_dims  n_layer  n_head  \\\n",
       "5      depth=4         -1            -1      20       12       8   \n",
       "6      depth=4         -1            -1      20       12       8   \n",
       "7      depth=4         -1            -1      20       12       8   \n",
       "4      depth=4         -1            -1      20       12       8   \n",
       "9                      -1            -1      20       12       8   \n",
       "10                     -1            -1      20       12       8   \n",
       "11                     -1            -1      20       12       8   \n",
       "8                      -1            -1      20       12       8   \n",
       "1   sparsity=3         -1            -1      20       12       8   \n",
       "2   sparsity=3         -1            -1      20       12       8   \n",
       "3   sparsity=3         -1            -1      20       12       8   \n",
       "0   sparsity=3         -1            -1      20       12       8   \n",
       "\n",
       "                              run_name  \n",
       "5             decision_tree_pretrained  \n",
       "6       decision_tree_pretrained_quant  \n",
       "7               decision_tree_standard  \n",
       "4         decision_tree_standard_quant  \n",
       "9         linear_regression_pretrained  \n",
       "10  linear_regression_pretrained_quant  \n",
       "11          linear_regression_standard  \n",
       "8     linear_regression_standard_quant  \n",
       "1         sparse_regression_pretrained  \n",
       "2   sparse_regression_pretrained_quant  \n",
       "3           sparse_regression_standard  \n",
       "0     sparse_regression_standard_quant  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_run_dir(run_dir)\n",
    "df  # list all the runs in our run_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c252b9b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>task</th>\n",
       "      <th>model</th>\n",
       "      <th>kwargs</th>\n",
       "      <th>num_tasks</th>\n",
       "      <th>num_examples</th>\n",
       "      <th>n_dims</th>\n",
       "      <th>n_layer</th>\n",
       "      <th>n_head</th>\n",
       "      <th>run_name</th>\n",
       "      <th>run_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pretrained</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>Transformer</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>linear_regression_pretrained</td>\n",
       "      <td>../models/linear_regression/pretrained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pretrained_quantized</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>Transformer</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>linear_regression_pretrained_quant</td>\n",
       "      <td>../models/linear_regression/pretrained_quantized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pretrained_relu</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>Transformer-ReLU</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>linear_regression_standard</td>\n",
       "      <td>../models/linear_regression/pretrained_relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pretrained_relu_quantized</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>Transformer-ReLU</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>linear_regression_standard_quant</td>\n",
       "      <td>../models/linear_regression/pretrained_relu_qu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      run_id               task             model kwargs  \\\n",
       "0                 pretrained  linear_regression       Transformer          \n",
       "1       pretrained_quantized  linear_regression       Transformer          \n",
       "2            pretrained_relu  linear_regression  Transformer-ReLU          \n",
       "3  pretrained_relu_quantized  linear_regression  Transformer-ReLU          \n",
       "\n",
       "   num_tasks  num_examples  n_dims  n_layer  n_head  \\\n",
       "0         -1            -1      20       12       8   \n",
       "1         -1            -1      20       12       8   \n",
       "2         -1            -1      20       12       8   \n",
       "3         -1            -1      20       12       8   \n",
       "\n",
       "                             run_name  \\\n",
       "0        linear_regression_pretrained   \n",
       "1  linear_regression_pretrained_quant   \n",
       "2          linear_regression_standard   \n",
       "3    linear_regression_standard_quant   \n",
       "\n",
       "                                            run_path  \n",
       "0             ../models/linear_regression/pretrained  \n",
       "1   ../models/linear_regression/pretrained_quantized  \n",
       "2        ../models/linear_regression/pretrained_relu  \n",
       "3  ../models/linear_regression/pretrained_relu_qu...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_trained_models(task: Union[\n",
    "        Literal[\"linear_regression\"], \n",
    "        Literal[\"sparse_linear_regression\"], \n",
    "        Literal[\"decision_tree\"], \n",
    "        Literal[\"relu_2nn_regression\"]\n",
    "    ] = \"linear_regression\"):\n",
    "    \n",
    "    models = df[df.task == task].reset_index(drop=True)\n",
    "    models[\"run_path\"] = models.apply(lambda row: os.path.join(run_dir, row['task'], row['run_id']), axis=1)\n",
    "    return models\n",
    "\n",
    "models = get_trained_models(\"linear_regression\")\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f961d4",
   "metadata": {},
   "source": [
    "## Plot Generation\n",
    "\n",
    "We will now directly load the model and measure its in-context learning ability on a larger batch of random inputs. (We expand the batch size to obtain better estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9334bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d2d6b70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bs_x = lambda factor: (lambda bs: bs * factor)\n",
    "bs = lambda batch_size: (lambda _: batch_size)\n",
    "scale = lambda factor: (lambda x: x * factor)\n",
    "\n",
    "optimals = {\n",
    "    \"linear_regression\" : {\n",
    "        \"error\": torch.concat((torch.arange(20, -1, -1), torch.zeros((21, )))),\n",
    "        \"label\" : \"Least Squares\"\n",
    "    }\n",
    "}\n",
    "\n",
    "naives = {\n",
    "    \"linear_regression\" : 20,\n",
    "    \"sparse_linear_regression\" : 3,\n",
    "    \"decision_tree\" : 1\n",
    "}\n",
    "\n",
    "def get_label(run_id):\n",
    "    return {\n",
    "        \"pretrained\" : \"Transformer\",\n",
    "        \"pretrained_relu\" : \"Transformer-ReLU\",\n",
    "        \"pretrained_quantized\" : \"Transformer-Int8\",\n",
    "        \"pretrained_relu_quantized\" : \"ReLU + Int8\"\n",
    "    }.get(run_id, \"Unknown\")\n",
    "\n",
    "def plot_model_errs(errors: Dict[str, torch.Tensor], baseline: int, optimal: Optional[Tuple[str, torch.Tensor]] = None, no_std_dev: bool = False):\n",
    "    for run_id, err in errors.items():\n",
    "        loss_means = err.mean(axis=0)\n",
    "        label_suffix = \"\" if no_std_dev else \"($\\mu \\; \\pm \\; 1\\sigma$)\"\n",
    "\n",
    "        plt.plot(loss_means, lw=2, label=f\"{get_label(run_id)} {label_suffix}\")\n",
    "\n",
    "        if not no_std_dev:\n",
    "            loss_stds  = err.std(axis=0)\n",
    "            plt.fill_between(list(range(loss_means.shape[0])), loss_means-loss_stds, loss_means+loss_stds, alpha=0.2, linewidth=0, antialiased=True)\n",
    "    \n",
    "    if optimal is not None:\n",
    "        plt.plot(optimal[1], label=optimal[0])\n",
    "    # if task in optimals.keys():\n",
    "    #     plt.plot(optimals[task][\"error\"], label=optimals[task][\"label\"])\n",
    "    plt.axhline(baseline, ls=\"--\", color=\"gray\", label=\"zero estimator\")\n",
    "    plt.xlabel(\"# in-context examples\")\n",
    "    plt.ylabel(\"squared error\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd499a57",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Error across all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1574043f-1290-46bb-a9ad-500e6d4461b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2048\n",
    "RUNS = 100\n",
    "\n",
    "def compute_errs(task):\n",
    "    models = get_trained_models(task)\n",
    "    errs = { \n",
    "        row[\"run_id\"] : get_err_from_run(\n",
    "            row[\"run_path\"], \n",
    "            mutate_bs=bs(BATCH_SIZE),\n",
    "            runs=RUNS,\n",
    "            ic_examples=MAX_CONTEXT_LENGTH\n",
    "        ).cpu()\n",
    "        for _, row in models.iterrows() \n",
    "    }\n",
    "    \n",
    "    return errs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50c5fdd-fe63-4b1b-88d9-80faf83469de",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aab61b-7653-49a6-b1e2-0e5647afa3f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running batches:  32%|███▏      | 32/100 [01:04<02:14,  1.97s/it]"
     ]
    }
   ],
   "source": [
    "task = \"linear_regression\"\n",
    "MAX_CONTEXT_LENGTH = 41\n",
    "errs = compute_errs(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23b3225-420f-45cf-8e9f-339287368939",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title(f\"Squared Error (avg over {RUNS} batches of {BATCH_SIZE})\")\n",
    "\n",
    "oracle = None\n",
    "if task in optimals.keys():\n",
    "    oracle = (optimals[task][\"label\"], optimals[task][\"error\"])\n",
    "    \n",
    "plot_model_errs(errs, baseline=naives[task], optimal=oracle)\n",
    "plt.xlim(0, 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d69088-3b1e-49f3-af2e-4e374a9744a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed8026b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task = \"decision_tree\"\n",
    "MAX_CONTEXT_LENGTH = 101\n",
    "errs = compute_errs(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a0e4b5-54e9-40f2-9546-874ee7309b4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title(f\"Squared Error (avg over {RUNS} batches of {BATCH_SIZE})\")\n",
    "\n",
    "oracle = None\n",
    "if task in optimals.keys():\n",
    "    oracle = (optimals[task][\"label\"], optimals[task][\"error\"])\n",
    "\n",
    "plot_model_errs(errs, baseline=naives[task], optimal=oracle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885885b3-e483-4e18-b829-9ee5506fbe7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Sparse Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0157ba5b-0ad2-4128-8091-634164af4282",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task = \"sparse_linear_regression\"\n",
    "MAX_CONTEXT_LENGTH = 41\n",
    "errs = compute_errs(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a626bd-1b31-4fcd-9153-2bf66c277f6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title(f\"Squared Error (avg over {RUNS} batches of {BATCH_SIZE})\")\n",
    "\n",
    "oracle = None\n",
    "if task in optimals.keys():\n",
    "    oracle = (optimals[task][\"label\"], optimals[task][\"error\"])\n",
    "\n",
    "plot_model_errs(errs, baseline=naives[task], optimal=oracle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae775a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Doubling Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5106a43a-2d77-46cf-87d1-2480f92236c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2048\n",
    "RUNS = 100\n",
    "double = scale(2)\n",
    "\n",
    "def compute_errs(task, context_length):\n",
    "    models = get_trained_models(task)\n",
    "    errs = { \n",
    "        row[\"run_id\"] : get_err_from_run(\n",
    "            row[\"run_path\"], \n",
    "            mutate_xs=double,\n",
    "            mutate_bs=bs(BATCH_SIZE),\n",
    "            runs=RUNS,\n",
    "            ic_examples=context_length\n",
    "        ).cpu()\n",
    "        for _, row in models.iterrows() \n",
    "    }\n",
    "    \n",
    "    return errs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14e2056-f97e-43fe-9cd9-3b21352326b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f004ff7-c47a-4b61-8892-b13e44fa412d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task = \"linear_regression\"\n",
    "errs = compute_errs(task, 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88bbe08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title(f\"Squared Error on doubled inputs (avg over {RUNS} batches of {BATCH_SIZE})\")\n",
    "\n",
    "oracle = None\n",
    "if task in optimals.keys():\n",
    "    oracle = (optimals[task][\"label\"], optimals[task][\"error\"] * double(1)**2)\n",
    "\n",
    "baseline = naives[task]\n",
    "if task in (\"linear_regression\", \"sparse_linear_regression\"):\n",
    "    baseline *= double(1)**2\n",
    "    \n",
    "plot_model_errs(\n",
    "    errs,\n",
    "    baseline=baseline,\n",
    "    optimal=oracle\n",
    "    # no_std_dev=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54df1508-2196-4e07-94a2-0783a7571624",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387f6b2e-bdb6-44d5-91c1-61eb1f5ec8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"decision_trees\"\n",
    "errs = compute_errs(task, 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04892835-7a5a-4fd2-83a1-1fc5ba906fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(f\"Squared Error on doubled inputs (avg over {RUNS} batches of {BATCH_SIZE})\")\n",
    "\n",
    "oracle = None\n",
    "if task in optimals.keys():\n",
    "    oracle = (optimals[task][\"label\"], optimals[task][\"error\"] * double(1)**2)\n",
    "\n",
    "baseline = naives[task]\n",
    "if task in (\"linear_regression\", \"sparse_linear_regression\"):\n",
    "    baseline *= double(1)**2\n",
    "    \n",
    "plot_model_errs(\n",
    "    errs,\n",
    "    baseline=baseline,\n",
    "    optimal=oracle\n",
    "    # no_std_dev=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7390c4c0-cac6-4c44-a4f7-46abc1519a61",
   "metadata": {},
   "source": [
    "#### Sparse Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2485bb-f684-4945-92a6-3b77a9ba6c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"sparse_linear_regression\"\n",
    "errs = compute_errs(task, 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac34270d-5584-4b44-9470-364c91283375",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(f\"Squared Error on doubled inputs (avg over {RUNS} batches of {BATCH_SIZE})\")\n",
    "\n",
    "oracle = None\n",
    "if task in optimals.keys():\n",
    "    oracle = (optimals[task][\"label\"], optimals[task][\"error\"] * double(1)**2)\n",
    "\n",
    "baseline = naives[task]\n",
    "if task in (\"linear_regression\", \"sparse_linear_regression\"):\n",
    "    baseline *= double(1)**2\n",
    "    \n",
    "plot_model_errs(\n",
    "    errs,\n",
    "    baseline=baseline,\n",
    "    optimal=oracle\n",
    "    # no_std_dev=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021f118e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Halving Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fa2955",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2048\n",
    "RUNS = 100\n",
    "halve = scale(0.5)\n",
    "\n",
    "def compute_errs(task, context_length):\n",
    "    models = get_trained_models(task)\n",
    "    errs = { \n",
    "        row[\"run_id\"] : get_err_from_run(\n",
    "            row[\"run_path\"], \n",
    "            mutate_xs=halve,\n",
    "            mutate_bs=bs(BATCH_SIZE),\n",
    "            runs=RUNS,\n",
    "            ic_examples=context_length\n",
    "        ).cpu()\n",
    "        for _, row in models.iterrows() \n",
    "    }\n",
    "    \n",
    "    return errs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cf3f64-cf00-4665-abc4-07c3bd2bf8b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980f1758-b570-440e-a3f6-6de43a52052a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task = \"linear_regression\"\n",
    "errs = compute_errs(task, 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8ab41f-1951-4b99-84f4-6b0c1f452b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title(f\"Squared Error on halved inputs (avg over {RUNS} batches of {BATCH_SIZE})\")\n",
    "\n",
    "oracle = None\n",
    "if task in optimals.keys():\n",
    "    oracle = (optimals[task][\"label\"], optimals[task][\"error\"] * halve(1)**2)\n",
    "\n",
    "baseline = naives[task]\n",
    "if task in (\"linear_regression\", \"sparse_linear_regression\"):\n",
    "    baseline *= halve(1)**2\n",
    "    \n",
    "plot_model_errs(\n",
    "    errs,\n",
    "    baseline=baseline,\n",
    "    optimal=oracle\n",
    "    # no_std_dev=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bcf823-a7f6-4c90-84da-fb477019b876",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d97f3a0-3db1-4b3e-b158-c2cb3125ad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"decision_tree\"\n",
    "errs = compute_errs(task, 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18efd8e3-dcf8-4b13-baa7-22bbf6ef7cec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title(f\"Squared Error on halved inputs (avg over {RUNS} batches of {BATCH_SIZE})\")\n",
    "\n",
    "oracle = None\n",
    "if task in optimals.keys():\n",
    "    oracle = (optimals[task][\"label\"], optimals[task][\"error\"] * halve(1)**2)\n",
    "\n",
    "baseline = naives[task]\n",
    "if task in (\"linear_regression\", \"sparse_linear_regression\"):\n",
    "    baseline *= halve(1)**2\n",
    "    \n",
    "plot_model_errs(\n",
    "    errs,\n",
    "    baseline=baseline,\n",
    "    optimal=oracle\n",
    "    # no_std_dev=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a8ca5b-986a-4a6e-84fc-dc71ecc185a0",
   "metadata": {},
   "source": [
    "#### Sparse Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddac4179-60ba-4b61-a931-8c91be59b168",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"sparse_linear_regression\"\n",
    "errs = compute_errs(task, 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0bd700-aea8-436d-b9a0-5ae877673584",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(f\"Squared Error on halved inputs (avg over {RUNS} batches of {BATCH_SIZE})\")\n",
    "\n",
    "oracle = None\n",
    "if task in optimals.keys():\n",
    "    oracle = (optimals[task][\"label\"], optimals[task][\"error\"] * halve(1)**2)\n",
    "\n",
    "baseline = naives[task]\n",
    "if task in (\"linear_regression\", \"sparse_linear_regression\"):\n",
    "    baseline *= halve(1)**2\n",
    "    \n",
    "plot_model_errs(\n",
    "    errs,\n",
    "    baseline=baseline,\n",
    "    optimal=oracle\n",
    "    # no_std_dev=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3e91bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Varying scaling factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edb5bd5-8b22-4202-a005-ab890cb2d31d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_scaling_errs(scales, models, bsize=256, runs=1, ic_examples=None):\n",
    "    errs = {}\n",
    "    \n",
    "    for _, row in models.iterrows():\n",
    "        print(f\"Computing error for {row['model']}\")\n",
    "        err = compute_scaling_err(row['run_path'], mutate_bs=bs(bsize), scales=scales, runs=runs, ic_examples=ic_examples).mean(axis=1)\n",
    "        errs[row['run_id']] = err\n",
    "\n",
    "    return errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3274bd78-4e7c-424e-b224-8d0a11df30e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_scaling_errs(errs, ic_example_counts, normalize_errs=True, max_y=50, task=\"linear_regression\"):\n",
    "    fig, ax = plt.subplots(1, len(ic_example_counts), sharey='all')\n",
    "    fig.set_size_inches(20, 5)\n",
    "    for i, ic_examples in enumerate(ic_example_counts):\n",
    "        for run_id, err in errs.items():\n",
    "            ys = err[:, ic_examples].cpu() / (scales ** 2) if normalize_errs else err[:, ic_examples]\n",
    "            ax[i].plot(scales, ys, label=get_label(run_id))\n",
    "\n",
    "        ax[i].set_title(f\"Error with {ic_examples} examples\")\n",
    "        ax[i].set_xscale('log')\n",
    "        ax[i].set_xlabel(\"Scaling factor\")\n",
    "        ax[i].set_ylim(0, max_y)\n",
    "\n",
    "        naive = naives[task]\n",
    "        if task in optimals.keys():\n",
    "            optim = torch.concat((optimals[task][\"error\"], torch.zeros((max(ic_example_counts)-19, ))))[ic_examples]\n",
    "        if normalize_errs: \n",
    "            ax[i].axhline(naive, ls=\"--\", color=\"gray\", label=\"zero estimator\")\n",
    "            if task in optimals.keys():\n",
    "                ax[i].axhline(optim, ls=\"--\", color=\"blue\", label=optimals[task][\"label\"])\n",
    "        else:\n",
    "            ax[i].set_yscale('log')\n",
    "\n",
    "            naive *= scales ** 2\n",
    "            ax[i].plot(naive, ls=\"--\", color=\"gray\", label=\"zero estimator\")\n",
    "            \n",
    "            if task in optimals.keys():\n",
    "                optim *= scales ** 2\n",
    "                ax[i].plot(optim, ls=\"--\", color=\"blue\", label=optimals[task][\"label\"])\n",
    "\n",
    "        if i == 0:\n",
    "            ax[i].set_ylabel(\"squared error\")\n",
    "\n",
    "        if i == 0:#len(ic_example_counts) - 1:\n",
    "            ax[i].legend()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02efaf41-719f-4b89-a490-adb5cfcd34fa",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50158847-db80-4196-897d-daae6c135357",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scales = np.concatenate((np.arange(0.1, 1, 0.1), np.arange(1, 11.)))\n",
    "models = get_trained_models(\"linear_regression\")\n",
    "scaling_errs = get_scaling_errs(scales, models, bsize=2048, runs=10, ic_examples=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d61549-edc5-49e2-b6ce-15ef435472af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = plot_scaling_errs(scaling_errs, [15, 20, 25, 30], max_y=50)\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5513ef1-6230-4c4c-a4df-df10a9c36014",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a385fef-56f0-419a-b71b-38b5ade33b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = np.concatenate((np.arange(0.1, 1, 0.1), np.arange(1, 11.)))\n",
    "models = get_trained_models(\"decision_tree\")\n",
    "scaling_errs = get_scaling_errs(scales, models, bsize=2048, runs=10, ic_examples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9656f5-49c8-4d85-a301-d0b151c614ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = plot_scaling_errs(scaling_errs, [30, 45, 60, 75, 90], max_y=1.2, task=\"decision_tree\")\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8378c7-ff4c-423c-b660-d422911684fa",
   "metadata": {},
   "source": [
    "#### Sparse Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c33ae6-d9b0-435f-afe1-dbd33fc9f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = np.concatenate((np.arange(0.1, 1, 0.1), np.arange(1, 11.)))\n",
    "models = get_trained_models(\"sparse_linear_regression\")\n",
    "scaling_errs = get_scaling_errs(scales, models, bsize=2048, runs=10, ic_examples=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38828775-3984-46d4-9f78-e78c8073ff03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Linear Reg\n",
    "plot_scaling_errs(scaling_errs, [15, 20, 25, 30], max_y=7, task=\"sparse_linear_regression\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a549d6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130a6c26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = get_trained_models(\"linear_regression\")\n",
    "BATCHES = [32, 64, 128, 256, 512, 1024, 2048, 4096]\n",
    "RUNS = 15\n",
    "\n",
    "run_data = {\n",
    "    row[\"model\"] : {\n",
    "        \"path\" : row[\"run_path\"],\n",
    "        \"errs\" : [], \"times\" : []\n",
    "    } for _, row in models.iterrows()\n",
    "}\n",
    "\n",
    "for batch in BATCHES:\n",
    "    print(f\"Running batch size of {batch} ... \", end='')\n",
    "    for model_type in run_data.keys():\n",
    "        err, time = get_timed_err_from_run(run_data[model_type][\"path\"], mutate_bs=(lambda bs: batch), runs=RUNS)\n",
    "        \n",
    "        run_data[model_type]['errs'].append(err.cpu())\n",
    "        run_data[model_type]['times'].append(time)\n",
    "\n",
    "for model_type in run_data.keys():\n",
    "    run_data[model_type]['errs'] = torch.stack(run_data[model_type]['errs']).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855a9f94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IC_EXAMPLES = [20]\n",
    "colors=[\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\", \"tab:brown\", \"tab:pink\", \"tab:gray\", \"tab:olive\", \"tab:cyan\",  \"black\", \"red\"]\n",
    "markers = [\"o\", \"^\", \".\" , \"s\" , \"P\" , \"v\" , \"1\", \"3\", \"*\", \"x\", \"d\", \"X\", \"8\"]\n",
    "\n",
    "for i, (marker, model_type) in enumerate(zip(markers, run_data.keys())):\n",
    "    x = np.array(run_data[model_type][\"times\"]).mean(axis=1)  * 1e3\n",
    "    y = run_data[model_type][\"errs\"][:, IC_EXAMPLES]\n",
    "    \n",
    "    for batch_time, ic, color in zip(x, BATCHES, colors):\n",
    "        if i == 0:\n",
    "            plt.axvline(batch_time, color=color, label=ic)\n",
    "        else:\n",
    "            plt.axvline(batch_time, color=color)\n",
    "\n",
    "    for ic, errs in zip(IC_EXAMPLES, y.T):\n",
    "        plt.plot(x, errs.cpu().numpy(), marker=marker, label=f\"{model_type} @ {ic}\")\n",
    "    \n",
    "plt.xscale('log')\n",
    "plt.title(f\"Inference time vs error for various batch sizes\")\n",
    "plt.xlabel(\"Time taken (ms)\")\n",
    "plt.ylabel(f\"Squared error @ {IC_EXAMPLES} examples\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0b2d93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RUNS = 10\n",
    "TIMING_BATCH_SIZE = 2048\n",
    "\n",
    "fixed_batch_size = lambda bs: TIMING_BATCH_SIZE\n",
    "\n",
    "# relu_abs_loss, time_relu = get_timed_err_from_run(run_path, mutate_bs=fixed_batch_size, runs=RUNS)\n",
    "# vanil_abs_loss, time_vanil = get_timed_err_from_run(\"../models/linear_regression/pretrained\", mutate_bs=fixed_batch_size, runs=RUNS)\n",
    "\n",
    "d = {}\n",
    "for _, row in models.iterrows():\n",
    "    err, time = get_timed_err_from_run(row[\"run_path\"], mutate_bs=bs(TIMING_BATCH_SIZE), runs=RUNS)\n",
    "    d[row[\"model\"]] = {\n",
    "        \"errs\" : err,\n",
    "        \"times\": time\n",
    "    }\n",
    "\n",
    "with open(\"losses_and_times.pkl\", 'wb') as f:\n",
    "    pickle.dump(d, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08e5ccb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"losses_and_times.pkl\", \"rb\") as f:\n",
    "    d = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb3908b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_times(times, title):\n",
    "    print(title, [t * 1e3 for t in times], f\"(mean: {np.mean(times)*1e3} +- {np.std(times)*1e3})\")\n",
    "format_times(d[\"Transformer-ReLU\"][\"times\"], \"ReLU Times :\")\n",
    "format_times(d[\"Transformer\"][\"times\"], \"Vanil Times:\")\n",
    "format_times(d[\"Transformer-Int8\"][\"times\"], \"Quant Times :\")\n",
    "format_times(d[\"ReLU + Int8\"][\"times\"], \"ReLU Quant Times:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4171bc9-0414-489e-9b94-4668103d1f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-in-context-learning-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-env-in-context-learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
